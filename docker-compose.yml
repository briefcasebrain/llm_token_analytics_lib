version: '3.8'

services:
  # Main API server
  api:
    build: .
    container_name: llm-analytics-api
    ports:
      - "5000:5000"
    environment:
      - PORT=5000
      - HOST=0.0.0.0
      - DEBUG=false
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/credentials/gcp.json
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./cache:/app/cache
      - ./results:/app/results
      - ./credentials:/app/credentials:ro
    restart: unless-stopped
    networks:
      - analytics-network

  # Dashboard service
  dashboard:
    build: .
    container_name: llm-analytics-dashboard
    command: python -c "from llm_token_analytics import create_dashboard; import pickle; results = pickle.load(open('/app/data/sample_results.pkl', 'rb')); app = create_dashboard(results); app.run_server(host='0.0.0.0', port=8050, debug=False)"
    ports:
      - "8050:8050"
    volumes:
      - ./data:/app/data:ro
      - ./results:/app/results:ro
    depends_on:
      - api
    networks:
      - analytics-network

  # Worker for background processing (optional)
  worker:
    build: .
    container_name: llm-analytics-worker
    command: python -c "import time; print('Worker started'); while True: time.sleep(60)"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_CLOUD_PROJECT=${GOOGLE_CLOUD_PROJECT}
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./cache:/app/cache
    networks:
      - analytics-network

  # PostgreSQL database (optional, for production)
  postgres:
    image: postgres:15-alpine
    container_name: llm-analytics-db
    environment:
      - POSTGRES_DB=llm_analytics
      - POSTGRES_USER=analytics
      - POSTGRES_PASSWORD=${DB_PASSWORD:-changeme}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - analytics-network

  # Redis for caching (optional)
  redis:
    image: redis:7-alpine
    container_name: llm-analytics-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - analytics-network

  # Nginx reverse proxy (optional, for production)
  nginx:
    image: nginx:alpine
    container_name: llm-analytics-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - api
      - dashboard
    networks:
      - analytics-network

networks:
  analytics-network:
    driver: bridge

volumes:
  postgres-data:
  redis-data:
